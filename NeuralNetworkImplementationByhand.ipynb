{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "images (InputLayer)          [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "hidden (Dense)               (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "48000/48000 [==============================] - 11s 228us/sample - loss: 0.6184 - accuracy: 0.7900 - val_loss: 0.4631 - val_accuracy: 0.8359\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 9s 181us/sample - loss: 0.4755 - accuracy: 0.8396 - val_loss: 0.4198 - val_accuracy: 0.8598\n",
      "Epoch 3/40\n",
      "48000/48000 [==============================] - 9s 184us/sample - loss: 0.4477 - accuracy: 0.8510 - val_loss: 0.4158 - val_accuracy: 0.8655\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 9s 178us/sample - loss: 0.4318 - accuracy: 0.8584 - val_loss: 0.4155 - val_accuracy: 0.8656\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 9s 188us/sample - loss: 0.4252 - accuracy: 0.8622 - val_loss: 0.4053 - val_accuracy: 0.8686\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 9s 189us/sample - loss: 0.4174 - accuracy: 0.8652 - val_loss: 0.4250 - val_accuracy: 0.8622\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 9s 187us/sample - loss: 0.4135 - accuracy: 0.8661 - val_loss: 0.3908 - val_accuracy: 0.8773\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.4092 - accuracy: 0.8684 - val_loss: 0.3948 - val_accuracy: 0.8807\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 9s 184us/sample - loss: 0.4066 - accuracy: 0.8701 - val_loss: 0.4042 - val_accuracy: 0.8707\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.4024 - accuracy: 0.8722 - val_loss: 0.3900 - val_accuracy: 0.8779\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 9s 180us/sample - loss: 0.4000 - accuracy: 0.8714 - val_loss: 0.3890 - val_accuracy: 0.8817\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 9s 189us/sample - loss: 0.3967 - accuracy: 0.8748 - val_loss: 0.4074 - val_accuracy: 0.8724\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.3976 - accuracy: 0.8755 - val_loss: 0.4018 - val_accuracy: 0.8748\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 9s 192us/sample - loss: 0.3948 - accuracy: 0.8750 - val_loss: 0.4061 - val_accuracy: 0.8757\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 9s 195us/sample - loss: 0.3914 - accuracy: 0.8783 - val_loss: 0.4042 - val_accuracy: 0.8802\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 9s 190us/sample - loss: 0.3913 - accuracy: 0.8789 - val_loss: 0.3995 - val_accuracy: 0.8776\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 9s 189us/sample - loss: 0.3927 - accuracy: 0.8777 - val_loss: 0.3916 - val_accuracy: 0.8792\n",
      "Epoch 18/40\n",
      "48000/48000 [==============================] - 9s 195us/sample - loss: 0.3888 - accuracy: 0.8787 - val_loss: 0.3931 - val_accuracy: 0.8820\n",
      "Epoch 19/40\n",
      "48000/48000 [==============================] - 9s 191us/sample - loss: 0.3862 - accuracy: 0.8809 - val_loss: 0.3871 - val_accuracy: 0.8833\n",
      "Epoch 20/40\n",
      "48000/48000 [==============================] - 9s 191us/sample - loss: 0.3855 - accuracy: 0.8810 - val_loss: 0.4075 - val_accuracy: 0.8739\n",
      "Epoch 21/40\n",
      "48000/48000 [==============================] - 9s 190us/sample - loss: 0.3903 - accuracy: 0.8790 - val_loss: 0.3935 - val_accuracy: 0.8808\n",
      "Epoch 22/40\n",
      "48000/48000 [==============================] - 9s 188us/sample - loss: 0.3854 - accuracy: 0.8806 - val_loss: 0.4077 - val_accuracy: 0.8767\n",
      "Epoch 23/40\n",
      "48000/48000 [==============================] - 9s 191us/sample - loss: 0.3861 - accuracy: 0.8813 - val_loss: 0.4086 - val_accuracy: 0.8741\n",
      "Epoch 24/40\n",
      "48000/48000 [==============================] - 9s 191us/sample - loss: 0.3840 - accuracy: 0.8820 - val_loss: 0.3965 - val_accuracy: 0.8813\n",
      "Epoch 25/40\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.3852 - accuracy: 0.8813 - val_loss: 0.3920 - val_accuracy: 0.8815\n",
      "Epoch 26/40\n",
      "48000/48000 [==============================] - 9s 189us/sample - loss: 0.3839 - accuracy: 0.8815 - val_loss: 0.3997 - val_accuracy: 0.8793\n",
      "Epoch 27/40\n",
      "48000/48000 [==============================] - 9s 186us/sample - loss: 0.3836 - accuracy: 0.8838 - val_loss: 0.3970 - val_accuracy: 0.8826\n",
      "Epoch 28/40\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.3833 - accuracy: 0.8836 - val_loss: 0.3994 - val_accuracy: 0.8813\n",
      "Epoch 29/40\n",
      "48000/48000 [==============================] - 9s 186us/sample - loss: 0.3809 - accuracy: 0.8839 - val_loss: 0.4007 - val_accuracy: 0.8780\n",
      "Epoch 30/40\n",
      "48000/48000 [==============================] - 9s 183us/sample - loss: 0.3800 - accuracy: 0.8841 - val_loss: 0.3963 - val_accuracy: 0.8830\n",
      "Epoch 31/40\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.3783 - accuracy: 0.8855 - val_loss: 0.3967 - val_accuracy: 0.8791\n",
      "Epoch 32/40\n",
      "48000/48000 [==============================] - 10s 207us/sample - loss: 0.3827 - accuracy: 0.8829 - val_loss: 0.3907 - val_accuracy: 0.8804\n",
      "Epoch 33/40\n",
      "48000/48000 [==============================] - 9s 184us/sample - loss: 0.3779 - accuracy: 0.8854 - val_loss: 0.4136 - val_accuracy: 0.8752\n",
      "Epoch 34/40\n",
      "48000/48000 [==============================] - 9s 185us/sample - loss: 0.3785 - accuracy: 0.8855 - val_loss: 0.4116 - val_accuracy: 0.8736\n",
      "Epoch 35/40\n",
      "48000/48000 [==============================] - 138s 3ms/sample - loss: 0.3770 - accuracy: 0.8848 - val_loss: 0.3864 - val_accuracy: 0.8834\n",
      "Epoch 36/40\n",
      "48000/48000 [==============================] - 9s 191us/sample - loss: 0.3776 - accuracy: 0.8845 - val_loss: 0.4025 - val_accuracy: 0.8777\n",
      "Epoch 37/40\n",
      "48000/48000 [==============================] - 9s 187us/sample - loss: 0.3802 - accuracy: 0.8846 - val_loss: 0.3948 - val_accuracy: 0.8807\n",
      "Epoch 38/40\n",
      "48000/48000 [==============================] - 9s 196us/sample - loss: 0.3776 - accuracy: 0.8845 - val_loss: 0.3881 - val_accuracy: 0.8836\n",
      "Epoch 39/40\n",
      "48000/48000 [==============================] - 765s 16ms/sample - loss: 0.3785 - accuracy: 0.8856 - val_loss: 0.3981 - val_accuracy: 0.8836\n",
      "Epoch 40/40\n",
      "48000/48000 [==============================] - 10s 211us/sample - loss: 0.3789 - accuracy: 0.8857 - val_loss: 0.4015 - val_accuracy: 0.8791\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "#from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.use('Agg')  # this is to set the matplotlib backend, you may not need\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## these could be read with an arg-parser\n",
    "reg_val = 0.0001\n",
    "dropout_rate = 0.3\n",
    "hideen_nodes = 100\n",
    "\n",
    "### such a small run, we can hide any GPUs and run on the CPU.\n",
    "### for small jobs, it can be faster on a CPU (true in this case)\n",
    "import os\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "os.environ['CUDA_VISIBLE_DEVICES']=''\n",
    "\n",
    "#### get the daatset\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "# train_images.shape is (60000, 28, 28)\n",
    "#test_images.shape (10000, 28, 28)\n",
    "num_pixels = 28 * 28 \n",
    "train_images = train_images.reshape( (60000, num_pixels) ).astype(np.float32) / 255.0\n",
    "test_images = test_images.reshape( (10000, num_pixels) ).astype(np.float32)  / 255.0\n",
    "\n",
    "# this uses the Functional API for definning the model\n",
    "nnet_inputs = Input(shape=(num_pixels,), name='images')\n",
    "z = Dense(hideen_nodes, activation='relu', kernel_regularizer=regularizers.l2(reg_val), bias_regularizer=regularizers.l2(reg_val), name='hidden')(nnet_inputs)\n",
    "z = Dropout(dropout_rate)(z)\n",
    "z = Dense(10, activation='softmax', kernel_regularizer=regularizers.l2(reg_val), bias_regularizer=regularizers.l2(reg_val), name='output')(z)\n",
    "\n",
    "our_first_model = Model(inputs=nnet_inputs, outputs=z)\n",
    "\n",
    "#this will print a summary of the model to the screen\n",
    "our_first_model.summary()\n",
    "\n",
    "#this will produce a digram of the model -- requires pydot and graphviz installed\n",
    "#plot_model(our_first_model, to_file='our_first_model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "our_first_model.compile(optimizer='adam', loss=SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "results = our_first_model.fit(train_images,  train_labels, batch_size=32, epochs=40, validation_split=0.2)\n",
    "\n",
    "# using a .hdf5 or .h5 extension saves the model in format compatible with older keras\n",
    "our_first_model.save('fmnist_trained.hdf5')\n",
    "\n",
    "# plot our learning curves\n",
    "#results.history is a dictionary\n",
    "loss = results.history['loss']\n",
    "val_loss = results.history['val_loss']\n",
    "acc = results.history['accuracy']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "epochs = np.arange(len(loss))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, label='loss')\n",
    "plt.plot(epochs, val_loss, label='val_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Multiclass Cross Entropy Loss')\n",
    "plt.title(f'Loss with{hideen_nodes} Hidden; Regularizer: {reg_val : 3.2g}; Dropout: {dropout_rate : 3.2g} ')\n",
    "plt.legend()\n",
    "plt.savefig(f'learning_loss_R_{reg_val}_D_{dropout_rate}_H_{hideen_nodes}.png', dpi=256)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, acc, label='acc')\n",
    "plt.plot(epochs, val_acc, label='val_acc')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(f'Accuracy with {hideen_nodes} Hidden; Regularizer: {reg_val : 3.2g}; Dropout: {dropout_rate : 3.2g} ')\n",
    "plt.legend()\n",
    "plt.savefig(f'learning_acc_R_{reg_val}_D_{dropout_rate}_H_{hideen_nodes}.png', dpi=256)\n",
    "\n",
    "# read back out model, just to illustrate\n",
    "model_copy = load_model('fmnist_trained.hdf5')\n",
    "\n",
    "# perform inference on a single image:\n",
    "prediction = model_copy.predict(test_images[0].reshape(1,num_pixels))\n",
    "num_classes = 10\n",
    "prediction = prediction.reshape(10)\n",
    "class_decision = np.argmax(prediction)\n",
    "for m in range(num_classes):\n",
    "\tif m == class_decision:\n",
    "\t\tprint(f'class{m}:\\tclass soft-decisions:{prediction[m]}\\t(hard decision)')\n",
    "\telse:\n",
    "\t\tprint(f'class{m}:\\tclass soft-decisions:{prediction[m]}')\n",
    "\n",
    "test_loss, test_acc = model_copy.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(f'Test Loss: {test_loss : 3.2f}')\n",
    "print(f'Test Accuracy: {100 * test_acc : 3.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
